{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "korean-wednesday",
      "metadata": {
        "id": "korean-wednesday"
      },
      "source": [
        "# Multilayer Perceptrons\n",
        "You should build an end-to-end machine learning pipeline using a multilayer perceptron model. In particular, you should do the following:\n",
        "- Load the `mnist` dataset using [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). You can find this dataset in the datasets folder.\n",
        "- Split the dataset into training and test sets using [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "- Build an end-to-end machine learning pipeline, including a [multilayer perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) model.\n",
        "- Optimize your pipeline by validating your design decisions.\n",
        "- Test the best pipeline on the test set and report various [evaluation metrics](https://scikit-learn.org/0.15/modules/model_evaluation.html).  \n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods of the model. Use them in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "infrared-copper",
      "metadata": {
        "id": "infrared-copper",
        "outputId": "4e081bd1-e864-4981-cc00-6f88114b900d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.DataFrame(load_digits().data)\n",
        "df['label'] = load_digits().target\n",
        "\n",
        "# Assuming first column = label\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# 2. Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Build pipeline\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# 4. Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'mlp__hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "    'mlp__activation': ['relu', 'tanh'],\n",
        "    'mlp__alpha': [0.0001, 0.001, 0.01],\n",
        "    'mlp__learning_rate_init': [0.001, 0.01],\n",
        "    'mlp__max_iter': [50, 100]\n",
        "}\n",
        "\n",
        "# 5. Optimize with Grid Search\n",
        "grid_search = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Best parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# 6. Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\nüéØ Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 7. Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - MLP on MNIST\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# 8. Inspect key model attributes\n",
        "mlp_model = best_model.named_steps['mlp']\n",
        "print(\"\\nüîç Model Summary:\")\n",
        "print(f\"Iterations run: {mlp_model.n_iter_}\")\n",
        "print(f\"Final loss: {mlp_model.loss_:.4f}\")\n",
        "print(f\"Number of layers (including input/output): {mlp_model.n_layers_}\")\n",
        "print(f\"Hidden layer sizes: {mlp_model.hidden_layer_sizes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sz0nd_dOLDyw"
      },
      "id": "Sz0nd_dOLDyw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}